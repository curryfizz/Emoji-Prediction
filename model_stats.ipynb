{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 06:00:51.739555: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 06:00:51.743013: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-01 06:00:51.798404: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-01 06:00:51.798453: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-01 06:00:51.798499: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 06:00:51.810446: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-01 06:00:51.811133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-01 06:00:53.428461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras.models import load_model, model_from_json\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "model_folder = \"models/training set v.3.0\"\n",
    "\n",
    "model_name = \"epochs_100_layers_55_50_45_40_35_30_25_20_10\"\n",
    "# model_name = \"epochs_15_layers_32_64_128_256\"\n",
    "\n",
    "model_json_path = f\"{model_folder}/json/{model_name}.json\"\n",
    "\n",
    "model_weight_path = f\"{model_folder}/weights/{model_name}.h5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 06:00:59.985870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-01 06:00:59.988244: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "json_file = open(f\"{model_json_path}\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(model_weight_path)\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emoji Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\n",
    "    0: \":red_heart:\",  # Love # X\n",
    "    1: \":face_with_tears_of_joy:\",  # Laughter X\n",
    "    2: \":grinning_face_with_big_eyes:\", # Happiness # X\n",
    "    3: \":loudly_crying_face:\",  # Sadness # X\n",
    "    4: \":smiling_face_with_heart-eyes:\",  # Adoration X\n",
    "    5: \":fire:\",  # Excitement X\n",
    "    6: \":thumbs_up:\",  # Approval\n",
    "    7: \":folded_hands:\",  # Gratitude X\n",
    "    8: \":angry_face:\",  # Anger X\n",
    "    9: \":thinking_face:\",  # Contemplation X\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get emoji from class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "    \"I am seeing what is happening\",\n",
    "    \"Does loading and unloading even work?\",\n",
    "    \"Naniii\",\n",
    "    \"Wtf is happening\",\n",
    "    \"Im dying\",\n",
    "    \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\",\n",
    "    \"I like your hoodie\",\n",
    "    \"Thank you for the help\",\n",
    "    \"Your jokes are so funny\",\n",
    "    \"I made it\",\n",
    "    \"You are so hot\",\n",
    "    \"I love you so much\",\n",
    "    \"Good job!\",\n",
    "    \"I am trying\", \"I want to cry\", \"This is just sad\",\n",
    "    \"I love sleeeping :)\",\n",
    "    \"Wait what is the syllabus even rip\",\n",
    "    \"slayyy\",\n",
    "    \"FIRE\",\n",
    "    \"If you're happy and you know it clap your hands\",\n",
    "    \"Less epochs is better huh?\",\n",
    "    \"Confusion matrices make it less confusing\",\n",
    "    \"Zero errors on first run are scary\",\n",
    "    \"THIS FINALLY WORKS MWAHAHAHA\",\n",
    "    \"Hapi hapi hapi\",\n",
    "    \"I love it when the code runs\",\n",
    "]\n",
    "\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "Xtest = pad_sequences(test_seq, maxlen=loaded_model.layers[0].input_shape[1], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See Results (emoji classes view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, 8, 3, 9, 9, 7, 1, 2, 5, 0, 1, 3, 3, 3, 0, 7, 9, 5, 4, 7,\n",
       "       2, 9, 9, 9, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(Xtest)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See results (actual emoji view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am seeing what is happening ğŸ¤”\n",
      "Does loading and unloading even work? ğŸ¤”\n",
      "Naniii ğŸ¤”\n",
      "Wtf is happening ğŸ˜ \n",
      "Im dying ğŸ˜­\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA ğŸ¤”\n",
      "I like your hoodie ğŸ¤”\n",
      "Thank you for the help ğŸ™\n",
      "Your jokes are so funny ğŸ˜‚\n",
      "I made it ğŸ˜ƒ\n",
      "You are so hot ğŸ”¥\n",
      "I love you so much â¤ï¸\n",
      "Good job! ğŸ˜‚\n",
      "I am trying ğŸ˜­\n",
      "I want to cry ğŸ˜­\n",
      "This is just sad ğŸ˜­\n",
      "I love sleeeping :) â¤ï¸\n",
      "Wait what is the syllabus even rip ğŸ™\n",
      "slayyy ğŸ¤”\n",
      "FIRE ğŸ”¥\n",
      "If you're happy and you know it clap your hands ğŸ˜\n",
      "Less epochs is better huh? ğŸ™\n",
      "Confusion matrices make it less confusing ğŸ˜ƒ\n",
      "Zero errors on first run are scary ğŸ¤”\n",
      "THIS FINALLY WORKS MWAHAHAHA ğŸ¤”\n",
      "Hapi hapi hapi ğŸ¤”\n",
      "I love it when the code runs â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print(test[i], label_to_emoji(y_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If you added test data and want to see accuracy metrics, follow the emoji dictionary and add classes in the labels array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (MSE): 10.851851851851851\n",
      "Test accuracy: 0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "# These values are subjective\n",
    "test_labels = [9,3,8,8,3,3,4,7,1,2,5,0,6,3,3,3,0,7,5,5,2,7,9,3,5,2,0]\n",
    "\n",
    "correct_predictions = np.sum(y_pred == test_labels)\n",
    "total_predictions = len(test_labels)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "\n",
    "# Calculate loss\n",
    "# Assuming you have a loss function defined or you're using a standard loss function like categorical crossentropy\n",
    "loss = 0.0\n",
    "for i in range(len(test_labels)):\n",
    "    true_label = test_labels[i]\n",
    "    predicted_value = y_pred[i]  \n",
    "    loss += (true_label - predicted_value) ** 2\n",
    "loss /= len(test_labels)\n",
    "print(f'Test loss (MSE): {loss}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy represented in an easy to understand visual format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTest Sentence                                                          | Predicted Emoji | True Emoji\u001b[0m\n",
      "\u001b[33m-----------------------------------------------------------------------|-----------------|-----------\u001b[0m\n",
      "\u001b[32mI am seeing what is happening                                          | ğŸ¤”\t\t | ğŸ¤”\u001b[0m\n",
      "\u001b[31mDoes loading and unloading even work?                                  | ğŸ¤”\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[31mNaniii                                                                 | ğŸ¤”\t\t | ğŸ˜ \u001b[0m\n",
      "\u001b[32mWtf is happening                                                       | ğŸ˜ \t\t | ğŸ˜ \u001b[0m\n",
      "\u001b[32mIm dying                                                               | ğŸ˜­\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[31mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA        | ğŸ¤”\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[31mI like your hoodie                                                     | ğŸ¤”\t\t | ğŸ˜\u001b[0m\n",
      "\u001b[32mThank you for the help                                                 | ğŸ™\t\t | ğŸ™\u001b[0m\n",
      "\u001b[32mYour jokes are so funny                                                | ğŸ˜‚\t\t | ğŸ˜‚\u001b[0m\n",
      "\u001b[32mI made it                                                              | ğŸ˜ƒ\t\t | ğŸ˜ƒ\u001b[0m\n",
      "\u001b[32mYou are so hot                                                         | ğŸ”¥\t\t | ğŸ”¥\u001b[0m\n",
      "\u001b[32mI love you so much                                                     | â¤ï¸\t\t | â¤ï¸\u001b[0m\n",
      "\u001b[31mGood job!                                                              | ğŸ˜‚\t\t | ğŸ‘\u001b[0m\n",
      "\u001b[32mI am trying                                                            | ğŸ˜­\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[32mI want to cry                                                          | ğŸ˜­\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[32mThis is just sad                                                       | ğŸ˜­\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[32mI love sleeeping :)                                                    | â¤ï¸\t\t | â¤ï¸\u001b[0m\n",
      "\u001b[32mWait what is the syllabus even rip                                     | ğŸ™\t\t | ğŸ™\u001b[0m\n",
      "\u001b[31mslayyy                                                                 | ğŸ¤”\t\t | ğŸ”¥\u001b[0m\n",
      "\u001b[32mFIRE                                                                   | ğŸ”¥\t\t | ğŸ”¥\u001b[0m\n",
      "\u001b[31mIf you're happy and you know it clap your hands                        | ğŸ˜\t\t | ğŸ˜ƒ\u001b[0m\n",
      "\u001b[32mLess epochs is better huh?                                             | ğŸ™\t\t | ğŸ™\u001b[0m\n",
      "\u001b[31mConfusion matrices make it less confusing                              | ğŸ˜ƒ\t\t | ğŸ¤”\u001b[0m\n",
      "\u001b[31mZero errors on first run are scary                                     | ğŸ¤”\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[31mTHIS FINALLY WORKS MWAHAHAHA                                           | ğŸ¤”\t\t | ğŸ”¥\u001b[0m\n",
      "\u001b[31mHapi hapi hapi                                                         | ğŸ¤”\t\t | ğŸ˜ƒ\u001b[0m\n",
      "\u001b[32mI love it when the code runs                                           | â¤ï¸\t\t | â¤ï¸\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "data = [(test[i], label_to_emoji(y_pred[i]), label_to_emoji(test_labels[i])) for i in range(len(test))]\n",
    "\n",
    "# Define headers\n",
    "headers = ['Test Sentence', 'Predicted Emoji', 'True Emoji']\n",
    "\n",
    "# Display the headers\n",
    "\n",
    "print(colored(f\"{headers[0]:<70} | {headers[1]:<1} | {headers[2]}\", 'yellow'))\n",
    "print(colored('-' * 71 + '|' + '-' * 17 + '|' + '-' * (len(headers[2])+1), 'yellow'))\n",
    "\n",
    "# Display the data\n",
    "for i in range(len(data)):\n",
    "    if data[i][1] == data[i][2]:\n",
    "        print(colored(f\"{data[i][0]:<70} | {data[i][1]}\\t\\t | {data[i][2]}\", 'green'))\n",
    "    else:\n",
    "        print(colored(f\"{data[i][0]:<70} | {data[i][1]}\\t\\t | {data[i][2]}\", 'red'))\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
