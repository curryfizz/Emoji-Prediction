{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras.models import load_model, model_from_json\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"models/training set v.3.0\"\n",
    "\n",
    "model_name = \"epochs_100_layers_55_50_45_40_35_30_25_20_10\"\n",
    "\n",
    "model_json_path = f\"{model_folder}/json/{model_name}.json\"\n",
    "\n",
    "model_weight_path = f\"{model_folder}/weights/{model_name}.h5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "json_file = open(f\"{model_json_path}\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(model_weight_path)\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get emoji from class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\n",
    "    0: \":red_heart:\",  # Love # X\n",
    "    1: \":face_with_tears_of_joy:\",  # Laughter X\n",
    "    2: \":grinning_face_with_big_eyes:\", # Happiness # X\n",
    "    3: \":loudly_crying_face:\",  # Sadness # X\n",
    "    4: \":smiling_face_with_heart-eyes:\",  # Adoration X\n",
    "    5: \":fire:\",  # Excitement X\n",
    "    6: \":thumbs_up:\",  # Approval\n",
    "    7: \":folded_hands:\",  # Gratitude X\n",
    "    8: \":angry_face:\",  # Anger X\n",
    "    9: \":thinking_face:\",  # Contemplation X\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "    \"I am seeing what is happening\",\n",
    "    \"Does loading and unloading even work?\",\n",
    "    \"Naniii\",\n",
    "    \"Wtf is happening\",\n",
    "    \"Im dying\",\n",
    "    \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\",\n",
    "    \"I like your hoodie\",\n",
    "    \"Thank you for the help\",\n",
    "    \"Your jokes are so funny\",\n",
    "    \"I made it\",\n",
    "    \"You are so hot\",\n",
    "    \"I love you so much\",\n",
    "    \"Good job!\",\n",
    "    \"I am trying\", \"I want to cry\", \"This is just sad\",\n",
    "    \"I love sleeeping :)\",\n",
    "    \"Wait what is the syllabus even rip\",\n",
    "    \"slayyy\",\n",
    "    \"FIRE\",\n",
    "    \"If you're happy and you know it clap your hands\"\n",
    "]\n",
    "\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "Xtest = pad_sequences(test_seq, maxlen=loaded_model.layers[0].input_shape[1], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, 8, 3, 9, 9, 7, 1, 2, 5, 0, 1, 3, 3, 3, 0, 7, 9, 5, 4],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(Xtest)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am seeing what is happening ü§î\n",
      "Does loading and unloading even work? ü§î\n",
      "Naniii ü§î\n",
      "Wtf is happening üò†\n",
      "Im dying üò≠\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA ü§î\n",
      "I like your hoodie ü§î\n",
      "Thank you for the help üôè\n",
      "Your jokes are so funny üòÇ\n",
      "I made it üòÉ\n",
      "You are so hot üî•\n",
      "I love you so much ‚ù§Ô∏è\n",
      "Good job! üòÇ\n",
      "I am trying üò≠\n",
      "I want to cry üò≠\n",
      "This is just sad üò≠\n",
      "I love sleeeping :) ‚ù§Ô∏è\n",
      "Wait what is the syllabus even rip üôè\n",
      "slayyy ü§î\n",
      "FIRE üî•\n",
      "If you're happy and you know it clap your hands üòç\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print(test[i], label_to_emoji(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (MSE): 6.809523809523809\n",
      "Test accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "test_labels = [9,3,8,8,3,3,4,7,1,2,5,0,6,3,3,3,0,7,5,5,2]\n",
    "\n",
    "correct_predictions = np.sum(y_pred == test_labels)\n",
    "total_predictions = len(test_labels)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "\n",
    "# Calculate loss\n",
    "# Assuming you have a loss function defined or you're using a standard loss function like categorical crossentropy\n",
    "loss = 0.0\n",
    "for i in range(len(test_labels)):\n",
    "    true_label = test_labels[i]\n",
    "    predicted_value = y_pred[i]  \n",
    "    loss += (true_label - predicted_value) ** 2\n",
    "loss /= len(test_labels)\n",
    "print(f'Test loss (MSE): {loss}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
