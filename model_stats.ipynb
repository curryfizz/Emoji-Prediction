{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras.models import load_model, model_from_json\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"models/training set v.3.0\"\n",
    "\n",
    "model_name = \"epochs_100_layers_55_50_45_40_35_30_25_20_10\"\n",
    "# model_name = \"epochs_15_layers_32_64_128_256\"\n",
    "\n",
    "model_json_path = f\"{model_folder}/json/{model_name}.json\"\n",
    "\n",
    "model_weight_path = f\"{model_folder}/weights/{model_name}.h5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "json_file = open(f\"{model_json_path}\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(model_weight_path)\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get emoji from class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\n",
    "    0: \":red_heart:\",  # Love # X\n",
    "    1: \":face_with_tears_of_joy:\",  # Laughter X\n",
    "    2: \":grinning_face_with_big_eyes:\", # Happiness # X\n",
    "    3: \":loudly_crying_face:\",  # Sadness # X\n",
    "    4: \":smiling_face_with_heart-eyes:\",  # Adoration X\n",
    "    5: \":fire:\",  # Excitement X\n",
    "    6: \":thumbs_up:\",  # Approval\n",
    "    7: \":folded_hands:\",  # Gratitude X\n",
    "    8: \":angry_face:\",  # Anger X\n",
    "    9: \":thinking_face:\",  # Contemplation X\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "    \"I am seeing what is happening\",\n",
    "    \"Does loading and unloading even work?\",\n",
    "    \"Naniii\",\n",
    "    \"Wtf is happening\",\n",
    "    \"Im dying\",\n",
    "    \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\",\n",
    "    \"I like your hoodie\",\n",
    "    \"Thank you for the help\",\n",
    "    \"Your jokes are so funny\",\n",
    "    \"I made it\",\n",
    "    \"You are so hot\",\n",
    "    \"I love you so much\",\n",
    "    \"Good job!\",\n",
    "    \"I am trying\", \"I want to cry\", \"This is just sad\",\n",
    "    \"I love sleeeping :)\",\n",
    "    \"Wait what is the syllabus even rip\",\n",
    "    \"slayyy\",\n",
    "    \"FIRE\",\n",
    "    \"If you're happy and you know it clap your hands\",\n",
    "    \"Less epochs is better huh?\",\n",
    "    \"Confusion matrices make it less confusing\",\n",
    "    \"Zero errors on first run are scary\",\n",
    "    \"THIS FINALLY WORKS MWAHAHAHA\",\n",
    "    \"Hapi hapi hapi\",\n",
    "    \"I love it when the code runs\",\n",
    "]\n",
    "\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "Xtest = pad_sequences(test_seq, maxlen=loaded_model.layers[0].input_shape[1], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, 8, 3, 9, 9, 7, 1, 2, 5, 0, 1, 3, 3, 3, 0, 7, 9, 5, 4, 7,\n",
       "       2, 9, 9, 9, 0], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(Xtest)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am seeing what is happening ğŸ¤”\n",
      "Does loading and unloading even work? ğŸ¤”\n",
      "Naniii ğŸ¤”\n",
      "Wtf is happening ğŸ˜ \n",
      "Im dying ğŸ˜­\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA ğŸ¤”\n",
      "I like your hoodie ğŸ¤”\n",
      "Thank you for the help ğŸ™\n",
      "Your jokes are so funny ğŸ˜‚\n",
      "I made it ğŸ˜ƒ\n",
      "You are so hot ğŸ”¥\n",
      "I love you so much â¤ï¸\n",
      "Good job! ğŸ˜‚\n",
      "I am trying ğŸ˜­\n",
      "I want to cry ğŸ˜­\n",
      "This is just sad ğŸ˜­\n",
      "I love sleeeping :) â¤ï¸\n",
      "Wait what is the syllabus even rip ğŸ™\n",
      "slayyy ğŸ¤”\n",
      "FIRE ğŸ”¥\n",
      "If you're happy and you know it clap your hands ğŸ˜\n",
      "Less epochs is better huh? ğŸ™\n",
      "Confusion matrices make it less confusing ğŸ˜ƒ\n",
      "Zero errors on first run are scary ğŸ¤”\n",
      "THIS FINALLY WORKS MWAHAHAHA ğŸ¤”\n",
      "Hapi hapi hapi ğŸ¤”\n",
      "I love it when the code runs â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print(test[i], label_to_emoji(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (MSE): 10.851851851851851\n",
      "Test accuracy: 0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "# These values are subjective\n",
    "test_labels = [9,3,8,8,3,3,4,7,1,2,5,0,6,3,3,3,0,7,5,5,2,7,9,3,5,2,0]\n",
    "\n",
    "correct_predictions = np.sum(y_pred == test_labels)\n",
    "total_predictions = len(test_labels)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "\n",
    "# Calculate loss\n",
    "# Assuming you have a loss function defined or you're using a standard loss function like categorical crossentropy\n",
    "loss = 0.0\n",
    "for i in range(len(test_labels)):\n",
    "    true_label = test_labels[i]\n",
    "    predicted_value = y_pred[i]  \n",
    "    loss += (true_label - predicted_value) ** 2\n",
    "loss /= len(test_labels)\n",
    "print(f'Test loss (MSE): {loss}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTest Sentence                                                          | Predicted Emoji | True Emoji\u001b[0m\n",
      "\u001b[33m-----------------------------------------------------------------------|-----------------|-----------\u001b[0m\n",
      "\u001b[32mI am seeing what is happening                                          | ğŸ¤”\t\t | ğŸ¤”\u001b[0m\n",
      "\u001b[31mDoes loading and unloading even work?                                  | ğŸ¤”\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[31mNaniii                                                                 | ğŸ¤”\t\t | ğŸ˜ \u001b[0m\n",
      "\u001b[32mWtf is happening                                                       | ğŸ˜ \t\t | ğŸ˜ \u001b[0m\n",
      "\u001b[32mIm dying                                                               | ğŸ˜­\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[31mAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA        | ğŸ¤”\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[31mI like your hoodie                                                     | ğŸ¤”\t\t | ğŸ˜\u001b[0m\n",
      "\u001b[32mThank you for the help                                                 | ğŸ™\t\t | ğŸ™\u001b[0m\n",
      "\u001b[32mYour jokes are so funny                                                | ğŸ˜‚\t\t | ğŸ˜‚\u001b[0m\n",
      "\u001b[32mI made it                                                              | ğŸ˜ƒ\t\t | ğŸ˜ƒ\u001b[0m\n",
      "\u001b[32mYou are so hot                                                         | ğŸ”¥\t\t | ğŸ”¥\u001b[0m\n",
      "\u001b[32mI love you so much                                                     | â¤ï¸\t\t | â¤ï¸\u001b[0m\n",
      "\u001b[31mGood job!                                                              | ğŸ˜‚\t\t | ğŸ‘\u001b[0m\n",
      "\u001b[32mI am trying                                                            | ğŸ˜­\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[32mI want to cry                                                          | ğŸ˜­\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[32mThis is just sad                                                       | ğŸ˜­\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[32mI love sleeeping :)                                                    | â¤ï¸\t\t | â¤ï¸\u001b[0m\n",
      "\u001b[32mWait what is the syllabus even rip                                     | ğŸ™\t\t | ğŸ™\u001b[0m\n",
      "\u001b[31mslayyy                                                                 | ğŸ¤”\t\t | ğŸ”¥\u001b[0m\n",
      "\u001b[32mFIRE                                                                   | ğŸ”¥\t\t | ğŸ”¥\u001b[0m\n",
      "\u001b[31mIf you're happy and you know it clap your hands                        | ğŸ˜\t\t | ğŸ˜ƒ\u001b[0m\n",
      "\u001b[32mLess epochs is better huh?                                             | ğŸ™\t\t | ğŸ™\u001b[0m\n",
      "\u001b[31mConfusion matrices make it less confusing                              | ğŸ˜ƒ\t\t | ğŸ¤”\u001b[0m\n",
      "\u001b[31mZero errors on first run are scary                                     | ğŸ¤”\t\t | ğŸ˜­\u001b[0m\n",
      "\u001b[31mTHIS FINALLY WORKS MWAHAHAHA                                           | ğŸ¤”\t\t | ğŸ”¥\u001b[0m\n",
      "\u001b[31mHapi hapi hapi                                                         | ğŸ¤”\t\t | ğŸ˜ƒ\u001b[0m\n",
      "\u001b[32mI love it when the code runs                                           | â¤ï¸\t\t | â¤ï¸\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "data = [(test[i], label_to_emoji(y_pred[i]), label_to_emoji(test_labels[i])) for i in range(len(test))]\n",
    "\n",
    "# Define headers\n",
    "headers = ['Test Sentence', 'Predicted Emoji', 'True Emoji']\n",
    "\n",
    "# Display the headers\n",
    "\n",
    "print(colored(f\"{headers[0]:<70} | {headers[1]:<1} | {headers[2]}\", 'yellow'))\n",
    "print(colored('-' * 71 + '|' + '-' * 17 + '|' + '-' * (len(headers[2])+1), 'yellow'))\n",
    "\n",
    "# Display the data\n",
    "for i in range(len(data)):\n",
    "    if data[i][1] == data[i][2]:\n",
    "        print(colored(f\"{data[i][0]:<70} | {data[i][1]}\\t\\t | {data[i][2]}\", 'green'))\n",
    "    else:\n",
    "        print(colored(f\"{data[i][0]:<70} | {data[i][1]}\\t\\t | {data[i][2]}\", 'red'))\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
