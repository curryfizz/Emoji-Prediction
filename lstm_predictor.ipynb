{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Embedding\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split  # Import for splitting the data\n",
    "from gensim.models import KeyedVectors\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/emoji_data/emoji_data.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emoji Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"emoji_dictionary = {\n",
    "    0: \":red_heart:\",  # Love\n",
    "    1: \":face_with_tears_of_joy:\",  # Laughter\n",
    "    2: \":smiling_face_with_heart-eyes:\",  # Adoration\n",
    "    3: \":loudly_crying_face:\",  # Sadness\n",
    "    4: \":fire:\",  # Excitement\n",
    "    5: \":thumbs_up:\",  # Approval\n",
    "    6: \":folded_hands:\",  # Gratitude\n",
    "    7: \":angry_face:\",  # Anger\n",
    "    8: \":sparkles:\",  # Happiness\n",
    "    9: \":weary_face:\",  # Exhaustion\n",
    "    10: \":astonished_face:\",  # Surprise\n",
    "    11: \":confused_face:\",  # Confusion\n",
    "    12: \":tropical_drink:\",  # Celebration\n",
    "    13: \":broken_heart:\",  # Heartbreak\n",
    "    14: \":thinking_face:\",  # Contemplation\n",
    "    15: \":sleeping_face:\",  # Sleepiness\n",
    "    16: \":victory_hand:\",  # Success\n",
    "    17: \":thumbs_down:\",  # Disapproval\n",
    "    18: \":grimacing_face:\",  # Discomfort\n",
    "    19: \":smiling_face_with_halo:\",  # Innocence\n",
    "}\"\"\"\n",
    "\n",
    "emoji_dictionary = {\n",
    "    0: \":red_heart:\",  # Love #\n",
    "    1: \":face_with_tears_of_joy:\",  # Laughter\n",
    "    2: \":grinning_face_with_big_eyes:\", # Happiness #\n",
    "    3: \":loudly_crying_face:\",  # Sadness #\n",
    "    4: \":smiling_face_with_heart-eyes:\",  # Adoration\n",
    "    5: \":fire:\",  # Excitement\n",
    "    6: \":thumbs_up:\",  # Approval\n",
    "    7: \":folded_hands:\",  # Gratitude\n",
    "    8: \":angry_face:\",  # Anger\n",
    "    9: \":thinking_face:\",  # Contemplation\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get labels from CLDR names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/emoji_data/emoji_data.csv', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[0].values\n",
    "Y = data[1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With glove dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# with open('data/glove_dataset/glove.6B.100d.txt','r', encoding='utf8') as file:\n",
    "#     content = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model_path = \"data/fast_text/crawl_dataset/crawl-300d-2M-subword.vec\"\n",
    "fasttext_model = KeyedVectors.load_word2vec_format(fasttext_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert FastText embeddings to a dictionary\n",
    "embeddings = {}\n",
    "for word in fasttext_model.index_to_key:\n",
    "    embeddings[word] = fasttext_model.get_vector(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = {}\n",
    "\n",
    "# for line in content:\n",
    "#     line = line.split()\n",
    "#     embeddings[line[0]] = np.array(line[1:], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With crawl dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model_path = \"data/fast_text/crawl_dataset/crawl-300d-2M-subword.vec\"\n",
    "fasttext_model = KeyedVectors.load_word2vec_format(fasttext_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert FastText embeddings to a dictionary\n",
    "embeddings = {}\n",
    "for word in fasttext_model.index_to_key:\n",
    "    embeddings[word] = fasttext_model.get_vector(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert input text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "word_to_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtokens = tokenizer.texts_to_sequences(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxlen(data):\n",
    "    maxlen = 0\n",
    "    for sent in data:\n",
    "        maxlen = max(maxlen, len(sent))\n",
    "    \n",
    "    return maxlen\n",
    "maxlen = get_maxlen(Xtokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pad_sequences(Xtokens, maxlen=maxlen, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Xtrain, Ytrain, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_to_index) + 1, embed_size))\n",
    "\n",
    "for word, i in word_to_index.items():\n",
    "    if word in embeddings:\n",
    "        embed_vector = embeddings[word]\n",
    "        embedding_matrix[i] = embed_vector\n",
    "    else:\n",
    "        # Handle out-of-vocabulary words or phrases by aggregating subword embeddings\n",
    "        phrase_embed_sum = None\n",
    "        for subword in word.split():\n",
    "            if subword in embeddings:\n",
    "                if phrase_embed_sum is None:\n",
    "                    phrase_embed_sum = embeddings[subword]\n",
    "                else:\n",
    "                    phrase_embed_sum += embeddings[subword]\n",
    "        if phrase_embed_sum is not None:\n",
    "            # Take the average of subword embeddings\n",
    "            embedding_matrix[i] = phrase_embed_sum / len(word.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general more layers >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "#units\n",
    "layers = [50, 100, 23, 67, 30, 20, 5, 10, 8, 9, 2, 256, 5]\n",
    "\n",
    "num_layers = len(layers)\n",
    "\n",
    "\n",
    "num_classes = len(emoji_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate file name for saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "def returnfilename():\n",
    "    layers_str = '_'.join(map(str, layers))  # Convert layers to string and join them with '_'\n",
    "    return f\"epochs_{epochs}_layers_{layers_str}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add Embedding layer\n",
    "model.add(Embedding(input_dim=len(word_to_index) + 1,\n",
    "                    output_dim=embed_size,\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False))\n",
    "\n",
    "\n",
    "# Add LSTM layers\n",
    "for i in range(num_layers):\n",
    "    # For the last layer, return_sequences=False\n",
    "    if i == num_layers - 1:\n",
    "        model.add(LSTM(units=layers[i]))\n",
    "    else:\n",
    "        model.add(LSTM(units=layers[i], return_sequences=True))\n",
    "\n",
    "# Add output Dense layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtrain, Ytrain, epochs=epochs,  verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = returnfilename()\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(f\"models/json/{filename}.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(f\"models/weights/{filename}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_folder = \"models/metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime('%d %B, %Y')\n",
    "\n",
    "# Write model architecture and details to file\n",
    "with open(f\"{metrics_folder}/{filename}.md\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"# Model description:<br>\\n\")\n",
    "    file.write(f\"Date generated: {formatted_datetime}<br>\\n\")\n",
    "    file.write(f\"Number of classes: {num_classes}<br>\\n\")\n",
    "    file.write(f\"Number of samples: {len(X)}<br>\\n\")\n",
    "    file.write(f\"Training set size: {len(X_train)}<br>\\n\")\n",
    "    file.write(f\"Test set size: {len(X_test)}<br>\\n\")\n",
    "    file.write(f\"Epochs used: {epochs}<br>\\n\")\n",
    "    file.write(f\"Number of layers: {num_layers}<br>\\n\")\n",
    "    file.write(f\"Layers used: {layers}<br>\\n\")\n",
    "    file.write(\"Optimizer: Adam<br>\\n\")\n",
    "    file.write(\"Loss function: Categorical Crossentropy<br>\\n\")\n",
    "    file.write(\"# Evaluation Results<br>\\n\")\n",
    "    file.write(f\"Test Loss: {loss:.4f}<br>\\n\")\n",
    "    file.write(f\"Test Accuracy: {accuracy:.4f}<br><br>\\n\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predicted and actual labels from one-hot encoded format to integer labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "Y_test_labels = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compare predicted labels with actual labels\n",
    "correct_predictions = np.sum(y_pred_labels == Y_test_labels)\n",
    "total_predictions = len(Y_test_labels)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Write accuracy to file\n",
    "with open(f\"{metrics_folder}/{filename}.md\", \"a\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"Accuracy: {:.4f}\\n\\n\".format(accuracy))\n",
    "\n",
    "\n",
    "# Write misclassified samples to file\n",
    "with open(f\"{metrics_folder}/{filename}.md\", \"a\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"## Misclassified samples:<br>\\n\")\n",
    "    for i in range(len(y_pred_labels)):\n",
    "        if y_pred_labels[i] != Y_test_labels[i]:\n",
    "            file.write(\n",
    "                f\"Predicted: {label_to_emoji(y_pred_labels[i])} Actual: {label_to_emoji(Y_test_labels[i])}<br>\\n\"\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(y_pred_labels)):\n",
    "    if y_pred_labels[i]!=Y_test_labels[i]:\n",
    "        print(\"Predicted:\", label_to_emoji(y_pred_labels[i]), \"Actual:\", label_to_emoji(Y_test_labels[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test = [\"I am trying\", \"I want to cry\", \"This is just sad\"]\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "Xtest = pad_sequences(test_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_pred = model.predict(Xtest)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Write predictions to file\n",
    "with open(f\"{metrics_folder}/{filename}.md\", \"a\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\n## Random test predictions: (accuracy based on discussion)<br>\\n\")\n",
    "    for i in range(len(test)):\n",
    "        file.write(f\"{test[i]} {label_to_emoji(y_pred[i])}<br>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(test)):\n",
    "    print(test[i], label_to_emoji(y_pred[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
