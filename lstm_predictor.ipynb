{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 01:30:33.161710: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-28 01:30:33.255545: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-28 01:30:33.255600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-28 01:30:33.258039: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-28 01:30:33.272618: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-28 01:30:34.711490: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import datetime\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Embedding\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split  # Import for splitting the data\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/emoji_data/emoji_data.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emoji Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "emoji_dictionary = {\n",
    "    0: \":red_heart:\",  # Love #\n",
    "    1: \":face_with_tears_of_joy:\",  # Laughter\n",
    "    2: \":grinning_face_with_big_eyes:\", # Happiness #\n",
    "    3: \":loudly_crying_face:\",  # Sadness #\n",
    "    4: \":smiling_face_with_heart-eyes:\",  # Adoration\n",
    "    5: \":fire:\",  # Excitement\n",
    "    6: \":thumbs_up:\",  # Approval\n",
    "    7: \":folded_hands:\",  # Gratitude\n",
    "    8: \":angry_face:\",  # Anger\n",
    "    9: \":thinking_face:\",  # Contemplation\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\n",
    "    0: \":red_heart:\",  # Love #\n",
    "    1: \":face_with_tears_of_joy:\",  # Laughter\n",
    "    2: \":grinning_face_with_big_eyes:\", # Happiness #\n",
    "    3: \":loudly_crying_face:\",  # Sadness #\n",
    "    4: \":smiling_face_with_heart-eyes:\",  # Adoration\n",
    "    5: \":fire:\",  # Excitement\n",
    "    6: \":thumbs_up:\",  # Approval\n",
    "    7: \":folded_hands:\",  # Gratitude\n",
    "    8: \":angry_face:\",  # Anger\n",
    "    9: \":thinking_face:\",  # Contemplation\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get labels from CLDR names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French macaroon is so tasty</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work is horrible</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good joke</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is your favorite baseball game</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I cooked meat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0  1\n",
       "0          French macaroon is so tasty  4\n",
       "1                     work is horrible  3\n",
       "2                            Good joke  1\n",
       "3  what is your favorite baseball game  9\n",
       "4                        I cooked meat  2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/emoji_data/emoji_data.csv', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[0].values\n",
    "Y = data[1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With glove dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# with open('data/glove_dataset/glove.6B.100d.txt','r', encoding='utf8') as file:\n",
    "#     content = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# embeddings = {}\n",
    "\n",
    "# for line in content:\n",
    "#     line = line.split()\n",
    "#     embeddings[line[0]] = np.array(line[1:], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With crawl dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model_path = \"data/fast_text/crawl_dataset/crawl-300d-2M-subword.vec\"\n",
    "fasttext_model = KeyedVectors.load_word2vec_format(fasttext_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert FastText embeddings to a dictionary\n",
    "embeddings = {}\n",
    "for word in fasttext_model.index_to_key:\n",
    "    embeddings[word] = fasttext_model.get_vector(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert input text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "word_to_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtokens = tokenizer.texts_to_sequences(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_maxlen(data):\n",
    "    maxlen = 0\n",
    "    for sent in data:\n",
    "        maxlen = max(maxlen, len(sent))\n",
    "    \n",
    "    return maxlen\n",
    "maxlen = get_maxlen(Xtokens)\n",
    "\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pad_sequences(Xtokens, maxlen=maxlen, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Xtrain, Ytrain, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_to_index) + 1, embed_size))\n",
    "\n",
    "for word, i in word_to_index.items():\n",
    "    if word in embeddings:\n",
    "        embed_vector = embeddings[word]\n",
    "        embedding_matrix[i] = embed_vector\n",
    "    else:\n",
    "        # Handle out-of-vocabulary words or phrases by aggregating subword embeddings\n",
    "        phrase_embed_sum = None\n",
    "        for subword in word.split():\n",
    "            if subword in embeddings:\n",
    "                if phrase_embed_sum is None:\n",
    "                    phrase_embed_sum = embeddings[subword]\n",
    "                else:\n",
    "                    phrase_embed_sum += embeddings[subword]\n",
    "        if phrase_embed_sum is not None:\n",
    "            # Take the average of subword embeddings\n",
    "            embedding_matrix[i] = phrase_embed_sum / len(word.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate file name for saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnfilename(prefix=\"\"):\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    formatted_datetime = current_datetime.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    filename = f\"{formatted_datetime}_epochs_{epochs}_layers_{layer1}_{layer2}_{layer3}_{layer4}\"\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general more layers >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "#units\n",
    "layer1 = 256\n",
    "layer2 = 16\n",
    "layer3 = 4\n",
    "layer4 = 2\n",
    "\n",
    "num_classes = len(emoji_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word_to_index) + 1,\n",
    "              output_dim=embed_size,\n",
    "              input_length=maxlen,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False),\n",
    "    LSTM(units=layer1, return_sequences=True),\n",
    "    LSTM(units=layer2, return_sequences=True),\n",
    "    LSTM(units=layer3, return_sequences=True),\n",
    "    LSTM(units=layer4),\n",
    "    Dense(num_classes, activation='softmax')  # Set output dimensionality to 20\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 00:41:56.402816: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-02-28 00:41:56.849195: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f8fe00b30d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-28 00:41:56.849251: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-02-28 00:41:56.870531: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709077317.115656   23123 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 9s 34ms/step - loss: 2.2994 - accuracy: 0.1221\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 2.2819 - accuracy: 0.1481\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.2602 - accuracy: 0.1481\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.2428 - accuracy: 0.1688\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 2.2265 - accuracy: 0.1740\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 2.2241 - accuracy: 0.1662\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.2194 - accuracy: 0.1714\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 2.2459 - accuracy: 0.1273\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 2.2246 - accuracy: 0.1610\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.2056 - accuracy: 0.1662\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.2033 - accuracy: 0.1481\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.1990 - accuracy: 0.1636\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.1956 - accuracy: 0.1740\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.1846 - accuracy: 0.1818\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1823 - accuracy: 0.1818\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 2.1722 - accuracy: 0.1974\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1779 - accuracy: 0.1844\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 2.1679 - accuracy: 0.1844\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 2.1685 - accuracy: 0.1922\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 2.1914 - accuracy: 0.1792\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.1515 - accuracy: 0.1948\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1333 - accuracy: 0.2026\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1339 - accuracy: 0.1896\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 2.1279 - accuracy: 0.1948\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 2.1223 - accuracy: 0.1896\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.1475 - accuracy: 0.1818\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 2.1424 - accuracy: 0.1896\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.1222 - accuracy: 0.2026\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.1180 - accuracy: 0.1948\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1783 - accuracy: 0.1688\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.1515 - accuracy: 0.1818\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 2.1799 - accuracy: 0.1688\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 2.1486 - accuracy: 0.2052\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1203 - accuracy: 0.2182\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.1083 - accuracy: 0.2104\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.0954 - accuracy: 0.2130\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 2.0849 - accuracy: 0.2260\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.0729 - accuracy: 0.2364\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.0825 - accuracy: 0.2130\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 2.0672 - accuracy: 0.2312\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.0811 - accuracy: 0.2260\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.0961 - accuracy: 0.2286\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 2.1500 - accuracy: 0.2078\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 2.1495 - accuracy: 0.2026\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.1370 - accuracy: 0.1922\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 2.0951 - accuracy: 0.2000\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 2.1047 - accuracy: 0.1740\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 2.1169 - accuracy: 0.1792\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 2.0936 - accuracy: 0.1974\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 2.0738 - accuracy: 0.2234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f905c5186a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, Ytrain, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "filename = returnfilename()\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(f\"models/json/{filename}.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(f\"models/weights/{filename}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 10ms/step - loss: 2.1009 - accuracy: 0.2078\n",
      "Test Loss: 2.100893974304199\n",
      "Test Accuracy: 0.20779220759868622\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 6ms/step\n",
      "Accuracy: 0.2077922077922078\n",
      "Predicted: 😃 Actual: ❤️\n",
      "Predicted: 🤔 Actual: 😠\n",
      "Predicted: 😃 Actual: 👍\n",
      "Predicted: 😃 Actual: 😍\n",
      "Predicted: 😃 Actual: 🤔\n",
      "Predicted: 🔥 Actual: 🙏\n",
      "Predicted: 😃 Actual: 😠\n",
      "Predicted: 😃 Actual: 🙏\n",
      "Predicted: 😃 Actual: 😠\n",
      "Predicted: 😃 Actual: 🔥\n",
      "Predicted: 😃 Actual: ❤️\n",
      "Predicted: 🔥 Actual: 😭\n",
      "Predicted: 😃 Actual: 🤔\n",
      "Predicted: 🤔 Actual: 😠\n",
      "Predicted: 😃 Actual: 👍\n",
      "Predicted: 😃 Actual: 👍\n",
      "Predicted: 😃 Actual: 😠\n",
      "Predicted: 🤔 Actual: 😠\n",
      "Predicted: 🔥 Actual: 😃\n",
      "Predicted: 🔥 Actual: 😭\n",
      "Predicted: 🤔 Actual: 😂\n",
      "Predicted: 😍 Actual: 😃\n",
      "Predicted: 🙏 Actual: 😭\n",
      "Predicted: 🔥 Actual: 👍\n",
      "Predicted: 😍 Actual: 😃\n",
      "Predicted: 🔥 Actual: 👍\n",
      "Predicted: 😃 Actual: ❤️\n",
      "Predicted: 😃 Actual: 🔥\n",
      "Predicted: 😃 Actual: 🔥\n",
      "Predicted: 😃 Actual: ❤️\n",
      "Predicted: 😍 Actual: 👍\n",
      "Predicted: 🤔 Actual: 😠\n",
      "Predicted: 🔥 Actual: 😃\n",
      "Predicted: 😃 Actual: 🔥\n",
      "Predicted: 😃 Actual: 😭\n",
      "Predicted: 😃 Actual: ❤️\n",
      "Predicted: 😍 Actual: 🔥\n",
      "Predicted: 😃 Actual: 😍\n",
      "Predicted: 😃 Actual: 👍\n",
      "Predicted: 😃 Actual: 🤔\n",
      "Predicted: 😍 Actual: 😭\n",
      "Predicted: 😃 Actual: ❤️\n",
      "Predicted: 🔥 Actual: 😭\n",
      "Predicted: 🤔 Actual: 🔥\n",
      "Predicted: 🤔 Actual: 😂\n",
      "Predicted: 😃 Actual: 🙏\n",
      "Predicted: 😃 Actual: ❤️\n",
      "Predicted: 🤔 Actual: 😠\n",
      "Predicted: 🤔 Actual: 😠\n",
      "Predicted: 😃 Actual: ❤️\n",
      "Predicted: 😃 Actual: ❤️\n",
      "Predicted: 😃 Actual: 🙏\n",
      "Predicted: 😃 Actual: 🙏\n",
      "Predicted: 🔥 Actual: 👍\n",
      "Predicted: 🤔 Actual: 😂\n",
      "Predicted: 😃 Actual: ❤️\n",
      "Predicted: 😃 Actual: 😭\n",
      "Predicted: 🤔 Actual: 👍\n",
      "Predicted: 😃 Actual: 😠\n",
      "Predicted: 🤔 Actual: 🙏\n",
      "Predicted: 🔥 Actual: 😭\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predicted and actual labels from one-hot encoded format to integer labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "Y_test_labels = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compare predicted labels with actual labels\n",
    "correct_predictions = np.sum(y_pred_labels == Y_test_labels)\n",
    "total_predictions = len(Y_test_labels)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display predicted labels and actual labels\n",
    "for i in range(len(y_pred_labels)):\n",
    "    if y_pred_labels[i]!=Y_test_labels[i]:\n",
    "        print(\"Predicted:\", label_to_emoji(y_pred_labels[i]), \"Actual:\", label_to_emoji(Y_test_labels[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "test = [\"I am trying\", \"I want to cry\", \"This is just sad\"]\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "Xtest = pad_sequences(test_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_pred = model.predict(Xtest)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am trying 😃\n",
      "I want to cry 🤔\n",
      "This is just sad 🤔\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print(test[i], label_to_emoji(y_pred[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
