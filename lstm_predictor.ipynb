{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 22:13:45.649113: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-24 22:13:45.754220: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-24 22:13:45.754281: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-24 22:13:45.756711: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-24 22:13:45.772899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-24 22:13:47.106713: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import datetime\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Embedding\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split  # Import for splitting the data\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emoji Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\n",
    "    0: \":red_heart:\",  # Love\n",
    "    1: \":face_with_tears_of_joy:\",  # Laughter\n",
    "    2: \":smiling_face_with_heart-eyes:\",  # Adoration\n",
    "    3: \":loudly_crying_face:\",  # Sadness\n",
    "    4: \":fire:\",  # Excitement\n",
    "    5: \":thumbs_up:\",  # Approval\n",
    "    6: \":folded_hands:\",  # Gratitude\n",
    "    7: \":angry_face:\",  # Anger\n",
    "    8: \":sparkles:\",  # Happiness\n",
    "    9: \":weary_face:\",  # Exhaustion\n",
    "    10: \":astonished_face:\",  # Surprise\n",
    "    11: \":confused_face:\",  # Confusion\n",
    "    12: \":tropical_drink:\",  # CelebrationS\n",
    "    13: \":broken_heart:\",  # Heartbreak\n",
    "    14: \":thinking_face:\",  # Contemplation\n",
    "    15: \":sleeping_face:\",  # Sleepiness\n",
    "    16: \":victory_hand:\",  # Success\n",
    "    17: \":thumbs_down:\",  # Disapproval\n",
    "    18: \":grimacing_face:\",  # Discomfort\n",
    "    19: \":smiling_face_with_halo:\",  # Innocence\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get labels from CLDR names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When your alarm goes off for the fifth time</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That moment when someone eats the last slice o...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When you finally finish a project</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Me trying to understand the group chat</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When the music is too loud at the party</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0   1\n",
       "0       When your alarm goes off for the fifth time    9\n",
       "1  That moment when someone eats the last slice o...   7\n",
       "2                 When you finally finish a project    8\n",
       "3            Me trying to understand the group chat   11\n",
       "4           When the music is too loud at the party   18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/emoji_data/emoji_data.csv', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "X = data[0].values\n",
    "Y = data[1].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With glove dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# with open('data/glove_dataset/glove.6B.100d.txt','r', encoding='utf8') as file:\n",
    "#     content = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# embeddings = {}\n",
    "\n",
    "# for line in content:\n",
    "#     line = line.split()\n",
    "#     embeddings[line[0]] = np.array(line[1:], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With crawl dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model_path = \"data/fast_text/crawl_dataset/crawl-300d-2M-subword.vec\"\n",
    "fasttext_model = KeyedVectors.load_word2vec_format(fasttext_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert FastText embeddings to a dictionary\n",
    "embeddings = {}\n",
    "for word in fasttext_model.index_to_key:\n",
    "    embeddings[word] = fasttext_model.get_vector(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert input text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "word_to_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtokens = tokenizer.texts_to_sequences(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_maxlen(data):\n",
    "    maxlen = 0\n",
    "    for sent in data:\n",
    "        maxlen = max(maxlen, len(sent))\n",
    "    \n",
    "    return maxlen\n",
    "maxlen = get_maxlen(Xtokens)\n",
    "\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pad_sequences(Xtokens, maxlen=maxlen, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Xtrain, Ytrain, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_to_index) + 1, embed_size))\n",
    "\n",
    "for word, i in word_to_index.items():\n",
    "    if word in embeddings:\n",
    "        embed_vector = embeddings[word]\n",
    "        embedding_matrix[i] = embed_vector\n",
    "    else:\n",
    "        # Handle out-of-vocabulary words or phrases by aggregating subword embeddings\n",
    "        phrase_embed_sum = None\n",
    "        for subword in word.split():\n",
    "            if subword in embeddings:\n",
    "                if phrase_embed_sum is None:\n",
    "                    phrase_embed_sum = embeddings[subword]\n",
    "                else:\n",
    "                    phrase_embed_sum += embeddings[subword]\n",
    "        if phrase_embed_sum is not None:\n",
    "            # Take the average of subword embeddings\n",
    "            embedding_matrix[i] = phrase_embed_sum / len(word.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate file name for saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnfilename(prefix=\"model\"):\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    formatted_datetime = current_datetime.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    filename = f\"{prefix}{formatted_datetime}_epochs_{epochs}_layers_{layer1}_{layer2}_{layer3}_{layer4}\"\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general more layers >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "#units\n",
    "layer1 = 256\n",
    "layer2 = 16\n",
    "layer3 = 4\n",
    "layer4 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 22:18:53.293756: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-24 22:18:53.373236: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-24 22:18:53.373650: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-24 22:18:53.377118: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-24 22:18:53.377474: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-24 22:18:53.377696: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-24 22:18:53.469169: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-24 22:18:53.469493: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-24 22:18:53.469731: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-24 22:18:53.469909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 981 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-02-24 22:18:53.721128: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word_to_index) + 1,\n",
    "              output_dim=embed_size,\n",
    "              input_length=maxlen,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False),\n",
    "    LSTM(units=layer1, return_sequences=True),\n",
    "    LSTM(units=layer2, return_sequences=True),\n",
    "    LSTM(units=layer3, return_sequences=True),\n",
    "    LSTM(units=layer4),\n",
    "    Dense(20, activation='softmax')  # Set output dimensionality to 20\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 22:19:00.921576: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-02-24 22:19:01.118103: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fcf2f6d1760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-24 22:19:01.118138: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-02-24 22:19:01.128613: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708809541.277676    7422 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 7s 19ms/step - loss: 2.9897 - accuracy: 0.0938\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.9790 - accuracy: 0.0875\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9700 - accuracy: 0.1125\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9623 - accuracy: 0.1125\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.9552 - accuracy: 0.1125\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9497 - accuracy: 0.1125\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.9438 - accuracy: 0.1125\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9387 - accuracy: 0.1125\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.9336 - accuracy: 0.1125\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9287 - accuracy: 0.1125\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.9218 - accuracy: 0.1125\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.9179 - accuracy: 0.1125\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.9097 - accuracy: 0.1375\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.9028 - accuracy: 0.1437\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8912 - accuracy: 0.1437\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8799 - accuracy: 0.1813\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8632 - accuracy: 0.1625\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8471 - accuracy: 0.2250\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8264 - accuracy: 0.1750\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8162 - accuracy: 0.1813\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8052 - accuracy: 0.2000\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.7856 - accuracy: 0.1750\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.7751 - accuracy: 0.2062\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7642 - accuracy: 0.1937\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.7478 - accuracy: 0.2000\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.7332 - accuracy: 0.2188\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.7210 - accuracy: 0.2562\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7081 - accuracy: 0.2500\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.6984 - accuracy: 0.2562\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.6912 - accuracy: 0.2688\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.6771 - accuracy: 0.2500\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.6668 - accuracy: 0.2812\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.6727 - accuracy: 0.2062\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6634 - accuracy: 0.2188\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6948 - accuracy: 0.2062\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7084 - accuracy: 0.1750\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6783 - accuracy: 0.1750\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.6819 - accuracy: 0.2125\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.6520 - accuracy: 0.2188\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6802 - accuracy: 0.1625\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6921 - accuracy: 0.1437\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.6669 - accuracy: 0.1562\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.6439 - accuracy: 0.1688\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.6175 - accuracy: 0.1750\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.5983 - accuracy: 0.2062\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5839 - accuracy: 0.2375\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5811 - accuracy: 0.2438\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5774 - accuracy: 0.2250\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.5681 - accuracy: 0.2438\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5595 - accuracy: 0.2438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd020708fa0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, Ytrain, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/curryfizz/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "filename = returnfilename()\n",
    "model.save(f\"models/{filename}.hdf5\")\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 2.5847 - accuracy: 0.1875\n",
      "Test Loss: 2.5847368240356445\n",
      "Test Accuracy: 0.1875\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Accuracy: 0.1875\n",
      "Predicted: 😕 Actual: ✌️\n",
      "Predicted: 💔 Actual: 👍\n",
      "Predicted: 😠 Actual: 😩\n",
      "Predicted: 😴 Actual: 😂\n",
      "Predicted: 😕 Actual: 😬\n",
      "Predicted: 😠 Actual: 😕\n",
      "Predicted: 😠 Actual: 🤔\n",
      "Predicted: 😕 Actual: 🙏\n",
      "Predicted: 😠 Actual: 😲\n",
      "Predicted: 😕 Actual: ✌️\n",
      "Predicted: 😕 Actual: 😩\n",
      "Predicted: 😠 Actual: 😭\n",
      "Predicted: 😠 Actual: 😬\n",
      "Predicted: 😠 Actual: 🍹\n",
      "Predicted: 😠 Actual: 😬\n",
      "Predicted: 😕 Actual: 😩\n",
      "Predicted: 😕 Actual: ✨\n",
      "Predicted: 😴 Actual: 😬\n",
      "Predicted: 😠 Actual: 😩\n",
      "Predicted: 😕 Actual: ✌️\n",
      "Predicted: 😕 Actual: 😩\n",
      "Predicted: 😠 Actual: 😬\n",
      "Predicted: 😠 Actual: 🤔\n",
      "Predicted: 😠 Actual: 🤔\n",
      "Predicted: 😕 Actual: 😇\n",
      "Predicted: 😠 Actual: 🙏\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predicted and actual labels from one-hot encoded format to integer labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "Y_test_labels = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compare predicted labels with actual labels\n",
    "correct_predictions = np.sum(y_pred_labels == Y_test_labels)\n",
    "total_predictions = len(Y_test_labels)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display predicted labels and actual labels\n",
    "for i in range(len(y_pred_labels)):\n",
    "    if y_pred_labels[i]!=Y_test_labels[i]:\n",
    "        print(\"Predicted:\", label_to_emoji(y_pred_labels[i]), \"Actual:\", label_to_emoji(Y_test_labels[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "test = [\"I am trying\", \"I want to cry\", \"This is just sad\"]\n",
    "test_seq = tokenizer.texts_to_sequences(test)\n",
    "Xtest = pad_sequences(test_seq, maxlen=maxlen, padding='post', truncating='post')\n",
    "y_pred = model.predict(Xtest)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am trying 😠\n",
      "I want to cry 😠\n",
      "This is just sad 😕\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print(test[i], label_to_emoji(y_pred[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
